@InProceedings{Buerhop2018,
  author    = {Buerhop-Lutz, Claudia and Deitsch, Sergiu and Maier, Andreas and Gallwitz, Florian and Berger, Stephan and Doll, Bernd and Hauch, Jens and Camus, Christian and Brabec, Christoph J.},
  title     = {A Benchmark for Visual Identification of Defective Solar Cells in Electroluminescence Imagery},
  booktitle = {European PV Solar Energy Conference and Exhibition (EU PVSEC)},
  year      = {2018},
  eventdate = {2018-09-24/2018-09-28},
  venue     = {Brussels, Belgium},
  doi       = {10.4229/35thEUPVSEC20182018-5CV.3.15},
}

@article{resNet2015,
	author    = {Kaiming He and	Xiangyu Zhang and Shaoqing Ren and Jian Sun},
	title     = {Deep Residual Learning for Image Recognition},
	journal   = {CoRR},
	year      = {2015},
	url       = {http://arxiv.org/abs/1512.03385},
	archivePrefix = {arXiv},
	eprint    = {1512.03385},
}


 @article{hjttrendKräling2022, 
 	title={PV Module Performance Measurements - Statistical Analysis of Technological Trends}, 
 	url={https://publica.fraunhofer.de/handle/publica/442552}, DOI={10.24406/publica-1430}, 
 	author={Kräling, Ulli and Gebhardt, Paul and Philipp, Daniel and Kaiser, Martin},
 	year={2022}}


@article{metricsPOLAK2009,
title = {An evaluation metric for image segmentation of multiple objects},
journal = {Image and Vision Computing},
volume = {27},
number = {8},
pages = {1223-1227},
year = {2009},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2008.09.008}   ,
url = {https://www.sciencedirect.com/science/article/pii/S0262885608001984},
author = {Mark Polak and Hong Zhang and Minghong Pi},
keywords = {Image segmentation, Evaluation, Error measure}
,
abstract = {It is important to be able to evaluate the performance of image segmentation algorithms objectively. In this paper, we define a new error measure which quantifies the performance of an image segmentation algorithm for identifying multiple objects in an image. This error measure is based on object-by-object comparisons of a segmented image and a ground-truth (reference) image. It takes into account the size, shape, and position of each object. Compared to existing error measures, our proposed error measure works at the object level, and is sensitive to both over-segmentation and under-segmentation. Hence, it can serve as a useful tool for comparing image segmentation algorithms and for tuning the parameters of a segmentation algorithm.}
}
@Article{Deitsch2021,
  author       = {Deitsch, Sergiu and Buerhop-Lutz, Claudia and Sovetkin, Evgenii and Steland, Ansgar and Maier, Andreas and Gallwitz, Florian and Riess, Christian},
  date         = {2021},
  journaltitle = {Machine Vision and Applications},
  title        = {Segmentation of photovoltaic module cells in uncalibrated electroluminescence images},
  doi          = {10.1007/s00138-021-01191-9},
  issn         = {1432-1769},
  number       = {4},
  volume       = {32},
}

@Article{Deitsch2019,
  author    = {Sergiu Deitsch and Vincent Christlein and Stephan Berger and Claudia Buerhop-Lutz and Andreas Maier and Florian Gallwitz and Christian Riess},
  title     = {Automatic classification of defective photovoltaic module cells in electroluminescence images},
  journal   = {Solar Energy},
  year      = {2019},
  volume    = {185},
  pages     = {455--468},
  month     = jun,
  issn      = {0038-092X},
  doi       = {10.1016/j.solener.2019.02.067},
  publisher = {Elsevier {BV}},
}
% ________________IMPORTED____________________
@inproceedings{CNNsCunHBB99,
  title = {Object Recognition with Gradient-Based Learning},
  author = {Yann LeCun and Patrick Haffner and Léon Bottou and Yoshua Bengio},
  year = {1999},
  url = {http://link.springer.de/link/service/series/0558/bibs/1681/16810319.htm},
  tags = {rule-based, meta-model, Meta-Environment, meta-objects},
  researchr = {https://researchr.org/publication/CunHBB99},
  cites = {0},
  citedby = {0},
  pages = {319},
  booktitle = {Shape, Contour and Grouping in Computer Vision},
  editor = {David A. Forsyth and Joseph L. Mundy and Vito Di Gesù and Roberto Cipolla},
  volume = {1681},
  series = {Lecture Notes in Computer Science},
  publisher = {Springer},
  isbn = {3-540-66722-9},
}

% This file was created with Citavi 6.14.0.0
@article{deepLearningLeCun2015,
author = {LeCun, Yann and Bengio, Y. and Hinton, Geoffrey},
year = {2015},
month = {05},
pages = {436-44},
title = {Deep Learning},
volume = {521},
journal = {Nature},
doi = {10.1038/nature14539}
}
@proceedings{.2019,
 year = {2019},
 title = {15th International Conference on Concentrator Photovoltaic Systems (CPV-15)},
 publisher = {{AIP Publishing}},
 series = {AIP Conference Proceedings}
}


@misc{UNETRonneberger2015,
 abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
 author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
 date = {2015},
 month = {05},
 day = {18},
 title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
 url = {http://arxiv.org/pdf/1505.04597v1}
}

@inproceedings{CityscapesCordts2016,
title={The Cityscapes Dataset for Semantic Urban Scene Understanding},
author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
booktitle={Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2016}
}

@misc{PL_imaging_Trupke_Bardos_Schubert_Warta_2006, 
title={Photoluminescence imaging of silicon wafers}, url={https://publica.fraunhofer.de/handle/publica/211746}, DOI={10.1063/1.2234747}, abstractNote={Photoluminescence imaging is demonstrated to be an extremely fast spatially resolved characterization technique for large silicon wafers. The spatial variation of the effective minority carrier lifetime is measured without being affected by minority carrier trapping or by excess carriers in space charge regions, effects that lead to experimental artifacts in other techniques. Photoluminescence imaging is contactless and can therefore be used for process monitoring before and after individual processing stages, for example, in photovoltaics research. Photoluminescence imaging is also demonstrated to be fast enough to be used as an in-line tool for spatially resolved characterization in an industrial environment.}, author={Trupke, T. and Bardos, R.A. and Schubert, M.C. and Warta, W.}, year={2006}}


@inproceedings{particle_image_Fischer2019,
 author = {Fischer, Andreas and Moldovan, Anamaria and Rentsch, Jochen},
 title = {Impact of vacuum grippers utilized for automated wafer handling prior a-Si passivation for silicon heterojunction solar cells},
 pages = {050002},
 publisher = {{AIP Publishing}},
 series = {AIP Conference Proceedings},
 booktitle = {15th International Conference on Concentrator Photovoltaic Systems (CPV-15)},
 year = {2019},
 doi = {10.1063/1.5123851}
}



@misc{bootstrapSelfSupGrill2020,
      title={Bootstrap your own latent: A new approach to self-supervised Learning}, 
      author={Jean-Bastien Grill and Florian Strub and Florent Altché and Corentin Tallec and Pierre H. Richemond and Elena Buchatskaya and Carl Doersch and Bernardo Avila Pires and Zhaohan Daniel Guo and Mohammad Gheshlaghi Azar and Bilal Piot and Koray Kavukcuoglu and Rémi Munos and Michal Valko},
      year={2020},
      eprint={2006.07733},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{emaHe2019,
  author       = {Kaiming He and
                  Haoqi Fan and
                  Yuxin Wu and
                  Saining Xie and
                  Ross B. Girshick},
  title        = {Momentum Contrast for Unsupervised Visual Representation Learning},
  journal      = {CoRR},
  volume       = {abs/1911.05722},
  year         = {2019},
  url          = {http://arxiv.org/abs/1911.05722},
  eprinttype    = {arXiv},
  eprint       = {1911.05722},
  timestamp    = {Mon, 02 Dec 2019 13:44:01 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1911-05722.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{imagenetdeng2009,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@InProceedings{Mask2Former_Cheng_2022_CVPR,
    author    = {Cheng, Bowen and Misra, Ishan and Schwing, Alexander G. and Kirillov, Alexander and Girdhar, Rohit},
    title     = {Masked-Attention Mask Transformer for Universal Image Segmentation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {06},
    year      = {2022},
    pages     = {1290-1299}
}

@article{stateOfTheArt_Mo_2022,
title = {Review the state-of-the-art technologies of semantic segmentation based on deep learning},
journal = {Neurocomputing},
volume = {493},
pages = {626-646},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222000054},
author = {Yujian Mo and Yan Wu and Xinneng Yang and Feilin Liu and Yujun Liao},
keywords = {Deep learning, Convolutional neural networks, Semantic segmentation, Real-time, Domain adaptation, Multi-modal fusion, Weakly-supervised},
abstract = {The goal of semantic segmentation is to segment the input image according to semantic information and predict the semantic category of each pixel from a given label set. With the gradual intellectualization of modern life, more and more applications need to infer relevant semantic information from images for subsequent processing, such as augmented reality, autonomous driving, video surveillance, etc. This paper reviews the state-of-the-art technologies of semantic segmentation based on deep learning. Because semantic segmentation requires a large number of pixel-level annotations, in order to reduce the fine-grained requirements of annotation and reduce the economic and time cost of manual annotation, this paper studies the works on weakly-supervised semantic segmentation. In order to enhance the generalization ability and robustness of the segmentation model, this paper investigates the works on domain adaptation in semantic segmentation. Many types of sensors are usually equipped in some practical applications, such as autonomous driving and medical image analysis. In order to mine the association between multi-modal data and improve the accuracy of the segmentation model, this paper investigates the works based on multi-modal data fusion semantic segmentation. The real-time performance of the model needs to be considered in practical application. This paper analyzes the key factors affecting the real-time performance of the segmentation model and investigates the works on real-time semantic segmentation. Finally, this paper summarizes the challenges and promising research directions of semantic segmentation tasks based on deep learning.}
}


@misc{dinov2Oquab.14.04.2023,
 abstract = {The recent breakthroughs in natural language processing for model pretraining on large quantities of data have opened the way for similar foundation models in computer vision. These models could greatly simplify the use of images in any system by producing all-purpose visual features, i.e., features that work across image distributions and tasks without finetuning. This work shows that existing pretraining methods, especially self-supervised methods, can produce such features if trained on enough curated data from diverse sources. We revisit existing approaches and combine different techniques to scale our pretraining in terms of data and model size. Most of the technical contributions aim at accelerating and stabilizing the training at scale. In terms of data, we propose an automatic pipeline to build a dedicated, diverse, and curated image dataset instead of uncurated data, as typically done in the self-supervised literature. In terms of models, we train a ViT model (Dosovitskiy et al., 2020) with 1B parameters and distill it into a series of smaller models that surpass the best available all-purpose features, OpenCLIP (Ilharco et al., 2021) on most of the benchmarks at image and pixel levels.},
 author = {Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and Assran, Mahmoud and Ballas, Nicolas and Galuba, Wojciech and Howes, Russell and Huang, Po-Yao and Li, Shang-Wen and Misra, Ishan and Rabbat, Michael and Sharma, Vasu and Synnaeve, Gabriel and Xu, Hu and Jegou, Herv{\'e} and Mairal, Julien and Labatut, Patrick and Joulin, Armand and Bojanowski, Piotr},
 date = {14.04.2023},
 title = {DINOv2: Learning Robust Visual Features without Supervision},
 url = {http://arxiv.org/pdf/2304.07193v1}
}


@misc{liu2023cuts,
      title={CUTS: A Fully Unsupervised Framework for Medical Image Segmentation}, 
      author={Chen Liu and Matthew Amodio and Liangbo L. Shen and Feng Gao and Arman Avesta and Sanjay Aneja and Jay Wang and Lucian V. Del Priore and Smita Krishnaswamy},
      year={2023},
      eprint={2209.11359},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{Li.21.09.2020,
 abstract = {In this paper, we propose a one-stage online clustering method called Contrastive Clustering (CC) which explicitly performs the instance- and cluster-level contrastive learning. To be specific, for a given dataset, the positive and negative instance pairs are constructed through data augmentations and then projected into a feature space. Therein, the instance- and cluster-level contrastive learning are respectively conducted in the row and column space by maximizing the similarities of positive pairs while minimizing those of negative ones. Our key observation is that the rows of the feature matrix could be regarded as soft labels of instances, and accordingly the columns could be further regarded as cluster representations. By simultaneously optimizing the instance- and cluster-level contrastive loss, the model jointly learns representations and cluster assignments in an end-to-end manner. Extensive experimental results show that CC remarkably outperforms 17 competitive clustering methods on six challenging image benchmarks. In particular, CC achieves an NMI of 0.705 (0.431) on the CIFAR-10 (CIFAR-100) dataset, which is an up to 19\% (39\%) performance improvement compared with the best baseline.},
 author = {Li, Yunfan and Hu, Peng and Liu, Zitao and Peng, Dezhong and Zhou, Joey Tianyi and Peng, Xi},
 date = {21.09.2020},
 title = {Contrastive Clustering},
 url = {http://arxiv.org/pdf/2009.09687v1}
}
@misc{threshholdAlamri2010,
      title={Image Segmentation by Using Threshold Techniques}, 
      author={Salem Saleh Al-amri and N. V. Kalyankar and Khamitkar S. D.},
      year={2010},
      eprint={1005.4020},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{clusterAxiomKeinberg2002,
author = {Kleinberg, Jon},
title = {An Impossibility Theorem for Clustering},
year = {2002},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
abstract = {Although the study of clustering is centered around an intuitively compelling goal, it has been very difficult to develop a unified framework for reasoning about it at a technical level, and profoundly diverse approaches to clustering abound in the research community. Here we suggest a formal perspective on the difficulty in finding such a unification, in the form of an impossibility theorem: for a set of three simple properties, we show that there is no clustering function satisfying all three. Relaxations of these properties expose some of the interesting (and unavoidable) trade-offs at work in well-studied clustering techniques such as single-linkage, sum-of-pairs, k-means, and k-median.},
booktitle = {Proceedings of the 15th International Conference on Neural Information Processing Systems},
pages = {463–470},
numpages = {8},
series = {NIPS'02}
}

@ARTICLE{Canny1986,
  author={Canny, John},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={A Computational Approach to Edge Detection}, 
  year={1986},
  volume={PAMI-8},
  number={6},
  pages={679-698},
  doi={10.1109/TPAMI.1986.4767851}}


@misc{evaluationMetricsUnsupervisedLearningAlgorithmsPalacioniño2019,
      title={Evaluation Metrics for Unsupervised Learning Algorithms}, 
      author={Julio-Omar Palacio-Niño and Fernando Berzal},
      year={2019},
      eprint={1905.05667},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{ObjectSegmentationOverviewWang_2022,
	doi = {10.1561/0600000097},
	url = {https://doi.org/10.1561%2F0600000097},
	year = 2022,
	publisher = {Now Publishers},
	volume = {13},
	number = {2-3},
	pages = {111--283},
	author = {Yuanbo Wang and Unaiza Ahsan and Hanyan Li and Matthew Hagen},
	title = {A Comprehensive Review of Modern Object Segmentation Approaches}, 
	journal = {Foundations and Trends{\textregistered} in Computer Graphics and Vision}
}

@misc{SAMKirillov2023,
 abstract = {We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision.},
 author = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and {Lo Wan-Yen} and Doll{\'a}r, Piotr and Girshick, Ross},
 year = {2023},
 title = {Segment Anything},
 url = {http://arxiv.org/pdf/2304.02643v1}
}


@misc{iicji2019,
      title={Invariant Information Clustering for Unsupervised Image Classification and Segmentation}, 
      author={Xu Ji and João F. Henriques and Andrea Vedaldi},
      year={2019},
      eprint={1807.06653},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{hwang2019segsort,
      title={SegSort: Segmentation by Discriminative Sorting of Segments}, 
      author={Jyh-Jing Hwang and Stella X. Yu and Jianbo Shi and Maxwell D. Collins and Tien-Ju Yang and Xiao Zhang and Liang-Chieh Chen},
      year={2019},
      eprint={1910.06962},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{semi_self_sementic_survey_Horlava.11.11.2020,
 abstract = {In recent years, Convolutional Neural Networks (CNNs) have become the state-of-the-art method for biomedical image analysis. However, these networks are usually trained in a supervised manner, requiring large amounts of labelled training data. These labelled data sets are often difficult to acquire in the biomedical domain. In this work, we validate alternative ways to train CNNs with fewer labels for biomedical image segmentation using. We adapt two semi- and self-supervised image classification methods and analyse their performance for semantic segmentation of biomedical microscopy images.},
 author = {Horlava, Nastassya and Mironenko, Alisa and Niehaus, Sebastian and Wagner, Sebastian and Roeder, Ingo and Scherf, Nico},
 date = {11.11.2020},
 title = {A comparative study of semi- and self-supervised semantic segmentation  of biomedical microscopy data},
 url = {http://arxiv.org/pdf/2011.08076v2}
}


@article{HongshanYu.2018,
 abstract = {Semantic segmentation, also called scene labeling, refers to the process of assigning a semantic label (e.g. car, people, and road) to each pixel of an image. It is an essential data processing step for robots and other unmanned systems to understand the surrounding scene. Despite decades of efforts, semantic segmentation is still a very challenging task due to large variations in natural scenes. In this paper, we provide a systematic review of recent advances in this field. In particular, three categories of methods are reviewed and compared, including those based on hand-engineered features, learned features and weakly supervised learning. In addition, we describe a number of popular datasets aiming for facilitating the development of new segmentation algorithms. In order to demonstrate the advantages and disadvantages of different semantic segmentation models, we conduct a series of comparisons between them. Deep discussions about the comparisons are also provided. Finally, this review is concluded by discussing future directions and challenges in this important field of research.},
 author = {{Hongshan Yu} and {Zhengeng Yang} and {Lei Tan} and {Yaonan Wang} and {Wei Sun} and {Mingui Sun} and {Yandong Tang}},
 year = {2018},
 title = {Methods and datasets on semantic segmentation: A review},
 url = {https://www.sciencedirect.com/science/article/pii/S0925231218304077},
 keywords = {3D point clouds labeling;Convolutional neural network;Markov random fields;Semantic segmentation;Weakly supervised method},
 pages = {82--103},
 volume = {304},
 issn = {0925-2312},
 journal = {Neurocomputing},
 doi = {10.1016/j.neucom.2018.03.037}
}


@misc{he2021masked,
      title={Masked Autoencoders Are Scalable Vision Learners}, 
      author={Kaiming He and Xinlei Chen and Saining Xie and Yanghao Li and Piotr Dollár and Ross Girshick},
      year={2021},
      eprint={2111.06377},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{vandenOord.10.07.2018,
 abstract = {While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.},
 author = {{van den Oord}, Aaron and Li, Yazhe and Vinyals, Oriol},
 date = {10.07.2018},
 title = {Representation Learning with Contrastive Predictive Coding},
 url = {http://arxiv.org/pdf/1807.03748v2}
}

@ARTICLE{otsu4310076,
  author={Otsu, Nobuyuki},
  journal={IEEE Transactions on Systems, Man, and Cybernetics}, 
  title={A Threshold Selection Method from Gray-Level Histograms}, 
  year={1979},
  volume={9},
  number={1},
  pages={62-66},
  doi={10.1109/TSMC.1979.4310076}}

@article{impactParticlesFischerrefId0,
	author = {{Fischer, Andreas} and {Vulcanean, Ioan Voicu} and {Pingel, Sebastian} and {Steinmetz, Anamaria}},
	title = {Impact of organic particles from wafer handling equipment on silicon heterojunction pseudo-efficiency},
	DOI= "10.1051/epjpv/2023023",
	url= "https://doi.org/10.1051/epjpv/2023023     ",
	journal = {EPJ Photovolt.},
	year = 2023,
	volume = 14,
	pages = "29",
}

@article{hungarian_Kuhn_1955,
author = {Kuhn, H. W.},
title = {The Hungarian method for the assignment problem},
journal = {Naval Research Logistics Quarterly},
volume = {2},
number = {1-2},
pages = {83-97},
doi = {https://doi.org/10.1002/nav.3800020109}           ,
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/nav.3800020109}              ,
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/nav.3800020109}             ,
abstract = {Abstract Assuming that numerical scores are available for the performance of each of n persons on each of n jobs, the “assignment problem” is the quest for an assignment of persons to jobs so that the sum of the n scores so obtained is as large as possible. It is shown that ideas latent in the work of two Hungarian mathematicians may be exploited to yield a new method of solving this problem.},
year = {1955}
}


@misc{STEGOhamilton2022unsupervised,
      title={Unsupervised Semantic Segmentation by Distilling Feature Correspondences}, 
      author={Mark Hamilton and Zhoutong Zhang and Bharath Hariharan and Noah Snavely and William T. Freeman},
      year={2022},
      eprint={2203.08414},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{ade20kZhou2018semantic,
      title={Semantic Understanding of Scenes through the ADE20K Dataset}, 
      author={Bolei Zhou and Hang Zhao and Xavier Puig and Tete Xiao and Sanja Fidler and Adela Barriuso and Antonio Torralba},
      year={2018},
      eprint={1608.05442},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{tray_img23, 
    author = "{Jonas \& Redmann Group GmbH}", 
    publisher = "Jonas & Redmann Group GmbH", 
    title = "HJT Tray Automation", 
    year = "2023", 
    url = "https://www.jonas-redmann.com/geschaeftsfelder/photovoltaik/tray-automation/",
    } 

@inproceedings{Fischer.2019,
 author = {Fischer, Andreas and Moldovan, Anamaria and Rentsch, Jochen},
 title = {Impact of vacuum grippers utilized for automated wafer handling prior a-Si passivation for silicon heterojunction solar cells},
 pages = {050002},
 publisher = {{AIP Publishing}},
 series = {AIP Conference Proceedings},
 booktitle = {15th International Conference on Concentrator Photovoltaic Systems (CPV-15)},
 year = {2019},
 doi = {10.1063/1.5123851}
}

@article{SHJDeWolfDescoeudresHolmanBallif2012,
url = {https://doi.org/10.1515/green-2011-0018}       ,
title = {High-efficiency Silicon Heterojunction Solar Cells: A Review},
title = {},
author = {Stefaan De Wolf and Antoine Descoeudres and Zachary C. Holman and Christophe Ballif},
pages = {7--24},
volume = {2},
number = {1},
journal = {Green},
doi = {doi:10.1515/green-2011-0018},
year = {2012},
lastchecked = {2023-10-25}
}

@inproceedings{Fischer.2019b,
 author = {Fischer, A. and Vulcanean and Moldovan, A. and Rentsch, J.},
 title = {Approach to clarify the cause of handling defects in silicon heterojunction cell production through the interplay of different imaging techniques},
 pages = {541--545},
 booktitle = {Proc. 36th Eur. Photovolt. Sol. Energy Conf. Exhib. Marseille, France},
 year = {2019}
}


@misc{ViTdosovitskiy2021image,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{collins2018deep,
      title={Deep Feature Factorization For Concept Discovery}, 
      author={Edo Collins and Radhakrishna Achanta and Sabine Süsstrunk},
      year={2018},
      eprint={1806.10206},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{cho2021picie,
      title={PiCIE: Unsupervised Semantic Segmentation using Invariance and Equivariance in Clustering}, 
      author={Jang Hyun Cho and Utkarsh Mall and Kavita Bala and Bharath Hariharan},
      year={2021},
      eprint={2103.17070},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{Transformer_Vaswani2017,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@misc{Chen.17.06.2020,
 abstract = {One paradigm for learning from few labeled examples while making best use of a large amount of unlabeled data is unsupervised pretraining followed by supervised fine-tuning. Although this paradigm uses unlabeled data in a task-agnostic way, in contrast to common approaches to semi-supervised learning for computer vision, we show that it is surprisingly effective for semi-supervised learning on ImageNet. A key ingredient of our approach is the use of big (deep and wide) networks during pretraining and fine-tuning. We find that, the fewer the labels, the more this approach (task-agnostic use of unlabeled data) benefits from a bigger network. After fine-tuning, the big network can be further improved and distilled into a much smaller one with little loss in classification accuracy by using the unlabeled examples for a second time, but in a task-specific way. The proposed semi-supervised learning algorithm can be summarized in three steps: unsupervised pretraining of a big ResNet model using SimCLRv2, supervised fine-tuning on a few labeled examples, and distillation with unlabeled examples for refining and transferring the task-specific knowledge. This procedure achieves 73.9{\%} ImageNet top-1 accuracy with just 1{\%} of the labels ({\$}\le{\$}13 labeled images per class) using ResNet-50, a {\$}10$\backslash$times{\$} improvement in label efficiency over the previous state-of-the-art. With 10{\%} of labels, ResNet-50 trained with our method achieves 77.5{\%} top-1 accuracy, outperforming standard supervised training with all of the labels.},
 author = {Chen, Ting and Kornblith, Simon and Swersky, Kevin and Norouzi, Mohammad and Hinton, Geoffrey},
 date = {17.06.2020},
 title = {Big Self-Supervised Models are Strong Semi-Supervised Learners},
 url = {http://arxiv.org/pdf/2006.10029v2}
}


@misc{caron2021emerging,
      title={Emerging Properties in Self-Supervised Vision Transformers}, 
      author={Mathilde Caron and Hugo Touvron and Ishan Misra and Hervé Jégou and Julien Mairal and Piotr Bojanowski and Armand Joulin},
      year={2021},
      eprint={2104.14294},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{he2020momentum,
      title={Momentum Contrast for Unsupervised Visual Representation Learning}, 
      author={Kaiming He and Haoqi Fan and Yuxin Wu and Saining Xie and Ross Girshick},
      year={2020},
      eprint={1911.05722},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{NEURIPS2020_70feb62b,
 author = {Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski, Piotr and Joulin, Armand},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {9912--9924},
 publisher = {Curran Associates, Inc.},
 title = {Unsupervised Learning of Visual Features by Contrasting Cluster Assignments},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/70feb62b69f16e0238f741fab228fec2-Paper.pdf},
 volume = {33},
 year = {2020}
}



@misc{AndreasFischerAnamariaMoldovanJochenRentsch.,
 author = {{Andreas Fischer, Anamaria Moldovan, Jochen Rentsch}},
 title = {Impact of Vacuum Grippers Utilized for Automated Wafer Handling Prior a-Si Passivation for Silicon Heterojunction Solar Cells}
}


@misc{A.FischerI.V.VulcaneanA.MoldovanJ.Rentsch.2019,
 author = {{A. Fischer, I.V. Vulcanean, A. Moldovan, J. Rentsch}},
 date = {2019},
 title = {APPROACH TO CLARIFY THE CAUSE OF HANDLING DEFECTS IN SILICON HETERO JUNCTION CELL PRODUCTION THROUGH THE INTERPLAY OF DIFFERENT IMAGING TECHNIQUES}
}


@proceedings{.2019b,
 year = {2019},
 title = {Proc. 36th Eur. Photovolt. Sol. Energy Conf. Exhib. Marseille, France}
}


@article{Fischer.2022,
 author = {Fischer, Andreas and Vulcanean, Ioan Voicu and Pingel, Sebastian and Moldovan, Anamaria and Rentsch, Jochen},
 year = {2022},
 title = {Impact of handling defects towards SHJ cell parameters},
 pages = {14},
 volume = {13},
 journal = {EPJ Photovoltaics},
 doi = {10.1051/epjpv/2022009}
}


@misc{wang2022contrastive,
      title={Contrastive Learning with Stronger Augmentations}, 
      author={Xiao Wang and Guo-Jun Qi},
      year={2022},
      eprint={2104.07713},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{GANisola2018imagetoimage,
      title={Image-to-Image Translation with Conditional Adversarial Networks}, 
      author={Phillip Isola and Jun-Yan Zhu and Tinghui Zhou and Alexei A. Efros},
      year={2018},
      eprint={1611.07004},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@inproceedings{GAN_GoodfelowNIPS2014_5ca3e9b1,
 author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Generative Adversarial Nets},
 url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf},
 volume = {27},
 year = {2014}
}

@INPROCEEDINGS{hadsell2006dimensionality,
  author={Hadsell, R. and Chopra, S. and LeCun, Y.},
  booktitle={2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)}, 
  title={Dimensionality Reduction by Learning an Invariant Mapping}, 
  year={2006},
  volume={2},
  number={},
  pages={1735-1742},
  doi={10.1109/CVPR.2006.100}}

@misc{grill2020bootstrap,
      title={Bootstrap your own latent: A new approach to self-supervised Learning}, 
      author={Jean-Bastien Grill and Florian Strub and Florent Altché and Corentin Tallec and Pierre H. Richemond and Elena Buchatskaya and Carl Doersch and Bernardo Avila Pires and Zhaohan Daniel Guo and Mohammad Gheshlaghi Azar and Bilal Piot and Koray Kavukcuoglu and Rémi Munos and Michal Valko},
      year={2020},
      eprint={2006.07733},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{jing2019selfsupervised,
      title={Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey}, 
      author={Longlong Jing and Yingli Tian},
      year={2019},
      eprint={1902.06162},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{koenig2023uncovering,
      title={Uncovering the Inner Workings of STEGO for Safe Unsupervised Semantic Segmentation}, 
      author={Alexander Koenig and Maximilian Schambach and Johannes Otterbach},
      year={2023},
      eprint={2304.07314},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
